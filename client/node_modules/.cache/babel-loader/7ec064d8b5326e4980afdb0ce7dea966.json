{"ast":null,"code":"import encodeWAV from './waveEncoder';\nimport getUserMedia from './getUserMedia';\nimport AudioContext from './AudioContext';\n\nvar WAVEInterface =\n/** @class */\nfunction () {\n  function WAVEInterface() {\n    this.recordingNodes = [];\n  }\n\n  Object.defineProperty(WAVEInterface.prototype, \"bufferLength\", {\n    get: function get() {\n      return this.buffers[0].length * WAVEInterface.bufferSize;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(WAVEInterface.prototype, \"audioDuration\", {\n    get: function get() {\n      return this.bufferLength / WAVEInterface.audioContext.sampleRate;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(WAVEInterface.prototype, \"audioData\", {\n    get: function get() {\n      return this.encodingCache || encodeWAV(this.buffers, this.bufferLength, WAVEInterface.audioContext.sampleRate);\n    },\n    enumerable: true,\n    configurable: true\n  });\n\n  WAVEInterface.prototype.startRecording = function () {\n    var _this = this;\n\n    return new Promise(function (resolve, reject) {\n      getUserMedia({\n        audio: true\n      }, function (stream) {\n        var audioContext = WAVEInterface.audioContext;\n        var recGainNode = audioContext.createGain();\n        var recSourceNode = audioContext.createMediaStreamSource(stream);\n        var recProcessingNode = audioContext.createScriptProcessor(WAVEInterface.bufferSize, 2, 2);\n        if (_this.encodingCache) _this.encodingCache = null;\n\n        recProcessingNode.onaudioprocess = function (event) {\n          if (_this.encodingCache) _this.encodingCache = null; // save left and right buffers\n\n          for (var i = 0; i < 2; i++) {\n            var channel = event.inputBuffer.getChannelData(i);\n\n            _this.buffers[i].push(new Float32Array(channel));\n          }\n        };\n\n        recSourceNode.connect(recGainNode);\n        recGainNode.connect(recProcessingNode);\n        recProcessingNode.connect(audioContext.destination);\n        _this.recordingStream = stream;\n\n        _this.recordingNodes.push(recSourceNode, recGainNode, recProcessingNode);\n\n        resolve(stream);\n      }, function (err) {\n        reject(err);\n      });\n    });\n  };\n\n  WAVEInterface.prototype.stopRecording = function () {\n    if (this.recordingStream) {\n      this.recordingStream.getTracks()[0].stop();\n      delete this.recordingStream;\n    }\n\n    for (var i in this.recordingNodes) {\n      this.recordingNodes[i].disconnect();\n      delete this.recordingNodes[i];\n    }\n  };\n\n  WAVEInterface.prototype.startPlayback = function (loop, onended) {\n    var _this = this;\n\n    if (loop === void 0) {\n      loop = false;\n    }\n\n    return new Promise(function (resolve, reject) {\n      var reader = new FileReader();\n      reader.readAsArrayBuffer(_this.audioData);\n\n      reader.onloadend = function () {\n        WAVEInterface.audioContext.decodeAudioData(reader.result, function (buffer) {\n          var source = WAVEInterface.audioContext.createBufferSource();\n          source.buffer = buffer;\n          source.connect(WAVEInterface.audioContext.destination);\n          source.loop = loop;\n          source.start(0);\n          source.onended = onended;\n          _this.playbackNode = source;\n          resolve(source);\n        });\n      };\n    });\n  };\n\n  WAVEInterface.prototype.stopPlayback = function () {\n    this.playbackNode.stop();\n  };\n\n  WAVEInterface.prototype.reset = function () {\n    if (this.playbackNode) {\n      this.playbackNode.stop();\n      this.playbackNode.disconnect(0);\n      delete this.playbackNode;\n    }\n\n    this.stopRecording();\n    this.buffers = [[], []];\n  };\n\n  WAVEInterface.audioContext = new AudioContext();\n  WAVEInterface.bufferSize = 2048;\n  return WAVEInterface;\n}();\n\nexport default WAVEInterface;","map":null,"metadata":{},"sourceType":"module"}